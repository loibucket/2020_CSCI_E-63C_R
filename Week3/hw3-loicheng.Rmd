---
title: 'CSCI E-63C: Week 3 Problem Set | Loi Cheng'
output:
  html_document:
    toc: yes
---

```{r setup, include=FALSE, results='hide'}
library(ggplot2)
library(ISLR)
knitr::opts_chunk$set(echo = TRUE)
```

# Preface

The goal of this week problem set is to practice basic tools available in R for developing linear regression models with one or more variables, to conduct visual and quantitative evaluation of their relative performance and to reason about associated tradeoffs.  We will continue working with the fund-raising dataset (which you have already downloaded and used for the previous week's problem set).  This time we will use some of the variables available there to develop a model of donors' contributions to the campaign of interest (attribute `contrib` in the `fund-raising.csv` file).  Given the complexity of the problem (it wouldn't be used for competition even twenty years ago otherwise) and limited number of attributes provided in this dataset, we should expect substantial fraction of variability in donors' contributions to remain unexplained as part of this exercise.  Furthermore, given strong correlations between some of the predictors in this dataset it is possible that only a subset of those could be justifiably used in the model (for the reasons related to collinearity - see Ch.3.3.3 section 6 of ISLR).

```{r readData, echo=FALSE, results='hide',fig.width=12,fig.height=12}
frcDat <- read.table("fund-raising.csv",sep=",",header=TRUE)
dim(frcDat)
pairs(frcDat)
```

Below, we will use the model of average donor contribution (attribute `avecontr`) and the total number of contributions by that donor (`ncontrib`) to illustrate tools available in R that will be needed for this problem set.  This is a good moment to pause and reflect on whether we have any expectations as to what the relationship between those two attributes could be.  Would we expect that those who give often also tend to make larger contributions on average?  Or, vice versa?  Or, we do not expect any well defined relationship between them? (You do not need to answer these questions as part of the problem set -- these are here only to stimulate your curiosity as you go through this preface.  The answers are shown immediately below anyway.)

We start with a simple linear model that can be fit using function `lm()` and summarized using `summary`:

```{r nAveContrib}
summary(lm(avecontr~ncontrib,frcDat))
```

Highly significant negative relationship between number of donations and average contribution.  On average, those who give frequently, tend to give less per donation.  Not a shocker, perhaps...

Let's overlay our model predictions on the actually observed data.  The plot of predictor and response with regression line added to it can be generated using standard R functions `plot` and `abline`.  Take a look at help page for `abline()`, this function is just a convenience tool for adding different types of straight lines to the plot, depending on the parameters. In our case, it is very useful that `abline()` knows how to deal with a fitted linear model object returned by `lm()`: it will extract the fitted intercept and slope and draw the corresponding line $y=ax+b$.  Vertical and horizontal dashes indicating $x=0$ and $y=0$ axes are also added using `abline` as shown below:

```{r nAvePlot}
plot(frcDat[,c("ncontrib","avecontr")])
abline(lm(avecontr~ncontrib,frcDat),col=2,lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)
```

Overall, not a terribly appealing plot with observations rather unevenly distributed along the model fit.  Additionally, for the highest numbers of contributions our model predicts negative average contribution that hardly makes sense for this problem.  Let's inspect this model's diagnostic plots.

Diagnostic plots for this model can be obtained also by the call to `plot` with the result of `lm()` used as input:

```{r nAveContrDiag,fig.width=8,fig.height=8}
old.par <- par(mfrow=c(2,2))
plot(lm(avecontr~ncontrib,frcDat))
par(old.par)
```

Also problematic...  Funnel-shaped plots of residuals vs. fitted suggest that the data may benefit from a transformation, quantile-quantile plot shows standardized residuals that are way outside of the range of theoretical quantiles (in other words, many of those residuals are way too large for the dataset size), and some of the points are close enough to Cook's distance of 0.5-1 for those contours to show up in residuals vs. leverage plot that is suggestive of problems with the model fit as well.

Let's see if fitting linear model to log-transformed (log base 10 for the ease of going from dollars to their log-transformed values in our heads) values of the number and average amount of the contribution is going to look any better:

```{r nAveContribLog}
summary(lm(log10(avecontr)~log10(ncontrib),frcDat))
```

Numerical values of the model coefficients are now obviously different, but the relationship remains the same -- those who give often, tend to give less on average per donation.

```{r nAvePlotLog}
plot(log10(frcDat[,c("ncontrib","avecontr")]))
abline(lm(log10(avecontr)~log10(ncontrib),frcDat),col=2,lwd=2)
```

Observations are now more evenly distributed around the fit.

```{r nAveContrLogDiag,fig.width=8,fig.height=8}
old.par <- par(mfrow=c(2,2))
plot(lm(log10(avecontr)~log10(ncontrib),frcDat))
par(old.par)
```

Aside from inevitably discrete fitted values for the lower end of the number of contributions (1, 2, 3, ...) the plots of residuals are now upon log-transformation much more like "shapeless clouds", standardized residuals are more on par with theoretical quantiles and no more contours representing Cook's distance of 0.5 and 1 (notice about an order of magnitude decrease in leverage values also).  Overall, far less troubling appearance of diagnostic plots.

We'll use this model for log-transformed data to get confidence and prediction intervals.  R functions `confint` returns confidence intervals for model parameters, while `predict` (with appropriate parameters) returns model predictions for the new data and (if asked), can also return corresponding estimates of uncertainty associated with them:

```{r nAveContrIntls}
confint(lm(log10(avecontr)~log10(ncontrib),frcDat))
10^predict(lm(log10(avecontr)~log10(ncontrib),frcDat),newdata=data.frame(ncontrib=c(9,10,11)),interval='confidence')
10^predict(lm(log10(avecontr)~log10(ncontrib),frcDat),newdata=data.frame(ncontrib=c(9,10,11)),interval='prediction')
```

Note the transformation of the confidence and prediction intervals on the model predictions to put it back onto the original scale of measurements (dollars).

# Problem 1: model of target contribution and last contribution (30 points)

Here we will identify the variable most correlated with the outcome (the donations to the campaign of interest - column `contrib` in `fund-raising.csv` file), build simple linear model for this outcome as a function of this variable, evaluate model summary and diagnostic plots and assess impact of using log-transformed (instead of untransformed) attributes on the model peformance.  The following steps provide approximate outline of tasks for achieving these goals:

1. Calculate correlations between all *continuous* attributes in this dataset.  Given potential non-linear relationship between some of the attributes and outcome, it might be prudent to use both Pearson and Spearman correlations to determine which variable is most robustly correlated with the target contributions (`contrib`).

**Review and clean data:**

```{r}
frcDat = read.table("fund-raising.csv",sep=",",header=TRUE)

frcDat$mindate = gsub('(.{2})', '\\1 ', frcDat$mindate) 
frcDat$mindate = as.Date(paste("01",frcDat$mindate , sep = ""), format = "%d %y %m")

frcDat$maxdate = gsub('(.{2})', '\\1 ', frcDat$maxdate) 
frcDat$maxdate = as.Date(paste("01",frcDat$maxdate , sep = ""), format = "%d %y %m")

head(frcDat)
```

```{r}
summary(frcDat)
```

**Review correlations**

```{r}
library('GGally')

"pearson (linear)"
p_cor = cor(  frcDat[sapply(frcDat, function(x) is.numeric(x))]  ,  method = "pearson"  )
round(p_cor, 2)

"spearman (rank)"
p_cor = cor(  frcDat[sapply(frcDat, function(x) is.numeric(x))]  ,  method = "spearman"  )
round(p_cor, 2)

```

**Visualize correlations**

```{r}

ggcorr(  frcDat[sapply(frcDat, function(x) is.numeric(x))]  , c("pairwise", "spearman")  , name = "spearman (linear)")

```

```{r}
ggcorr(  frcDat[sapply(frcDat, function(x) is.numeric(x))]  , c("pairwise", "pearson")  , name = "pearson (ranked)" )

```

**The data shows very high correlation between avecontr~lastcontr, avecontr~maxcontrib, lastcontr~maxcontrib, ncontrib~promocontr.  The contrib is most correlated with maxcontrib, lastcontr and avecontr.**

2. Fit linear model for target campaign contribution as the outcome and the last contribution by this donor (`lastcontr` in `fund-raising.csv`) the predictor, using R function `lm`; inspect the fitted model using `summary` function, and use the output to answer the following questions:

```{r}
summary(lm(contrib~lastcontr,frcDat))
```

   + Does this predictor explain significant amount of variability in response?  I.e. is there statistically (!) significant association between them?
   
**Yes there is significant association between them.  The p-value is nearly zero.**
   
   + What is the RSE and $R^2$ of this model?  Remember, you can find them in the `summary` output or use `sigma` and `r.sq` slots in the result returned by `summary` instead (the `summary()` command does return a *list*; if instead of just printing the result into the console you save it into a variable, as in `model.summary <- summary(...)`, you can verify that the content of that variable *is* a list, you can see with `names(model.summary)` which elements this list contains, and you can extract, examine, and use them at will if you ever need to)
   
**The RSE is 7.69 on 3468 degrees of freedom.  The $R^2$ is 0.557**
   
   + What are the model coefficients and what would be their interpretation? What is the meaning of the intercept of the model, for example?  What about the slope - how would you interpret its value?

**The model coefficients are the constants in the linear model formula.  The formula is contrib = 3.523 + 0.79523*lastcontr.  This line is plotted as green squares in the plot below, which overlaps the red line created by the lm function.  This model predicts that a donor would contribute $3.52, plus an additional $0.80 for every $1 previously contributed.** 

3. Create scatterplot of target campaign contribution and the last contribution (the attributes used in the model above) and add to the plot the regression line from the model using `abline` function

```{r ,fig.width=8,fig.height=8}

x = (1:50)*5
y = 3.52300 + x*0.79523

plot(frcDat[,c("lastcontr","contrib")])
abline(lm(contrib~lastcontr,frcDat),col=2,lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)

points(x,y,col=3,pch=15)

```
**The scatter plot shows some outliers, for example a dontor with $50 lastcontr and $200 contrib, which is relatively very far from the regression line.**

4. Create diagnostic plots of the model and comment on any irregularities that they present.  For instance, does the plot of residuals vs. fitted values suggest presence of non-linearity that remains unexplained by the model?  Does scale-location plot suggest non-uniformity of variance along the range of fitted values?  Are some standardized residuals far greater than theoretical quantiles?  What about residuals vs. leverage plot and Cook's distance contours therein?  How does your conclusions compare to what's shown in the plot of the predictor and outcome with regression line added to it -- i.e. the plot that was generated above?

```{r ,fig.width=8,fig.height=8}
old.par <- par(mfrow=c(2,2))
plot(lm(contrib~lastcontr,frcDat))
par(old.par)

```
```{r}
frcDat[c(1148,1242,3344),c('contrib','lastcontr')]
```
**The Residuals vs Fitted shows there are some outliers that cannot be explained by this model.  For example, rows 1148,1242,3344 has a very high contrib relative to lastcontr, which the model would not have predicted.  The Scale Location plot indicates that the variance of residuals increases with increasing lastcontr amounts.  The QQ plot indicates the model has a good fit between -2 and +2 quantiles, which is about 95% of the data.  These observations are consistent with the plot of the predictor and outcome.  The Cooks distances show that all the points are within a distance of 1, so including or excluding an outlier such as 1242 does not make a significant change to the model.** 

5. Use function `confint` to obtain 95% confidence intervals on model parameters
```{r}
confint(lm(contrib~lastcontr,frcDat))
```
6. Use this model and `predict` function to make predictions for the last contribution values of 10, 20 and 40. Remember that when you pass new data to `predict`, you have to make sure that the variable (column) names in those data match the predictor variable name(s) used in the model, otherwise `predict` will not know how to match the data to the model variables! Use `confidence` and `prediction` settings for parameter `interval` in the call to `predict` to obtain 90% confidence and prediction intervals on these model predictions (please double check what is default confidence level used by those functions and adjust if/as necessary).  Explain the differences between interpretation of:
    + confidence intervals on model parameters and model predictions
    + confidence and prediction intervals on model predictions
    + comment on whether confidence or prediction intervals (on predictions) are wider and why
```{r}
predict(  lm(contrib~lastcontr,frcDat),newdata=data.frame(lastcontr=c(10,20,40)),interval='confidence', level = 0.9)

predict(  lm(contrib~lastcontr,frcDat),newdata=data.frame(lastcontr=c(10,20,40)),interval='prediction', level = 0.9)

```
**Confidence intervals on model parameters indicate that if we take 100 random pairs of (contrib and lastcontr) from the data and look at each one separately, for 90 of them, we can find an intercept constant between 3.09 and 3.96, and a lastcontr constant between 0.77 and 0.82, such that if we draw this line, it would intersect the point made by the pair.**

**The confidence and prediction intervals on model predictions are plotted below.  The wider orange lines are the prediction intervals and the narrow blue lines are the confidence intervals.**

**Confidence intervals on model predictions indicates that if we have 100 sets of fund_raising.csv data, and for each of them take the mean of contrib values for one lastcontr value, such as 10, 90 of these mean values would be between this interval of 11.95 and 11.76.  In the plot below, if we take plot the mean value of contrib for each lastcontr, we expect 90% of the points to be within the narrow blue lines.**

**Prediction intervals on model predictions indciates that if we randomly take 100 contrib values for a given lastcontr value, such as 10, 90 of them would be between this interval of -3.61 and 26.56.  We know contribution cannot be less than zero, so realistically, this interval is 0 to 26.56.  If we randomly select 100 points from the plot below, we expect to have 90 of them inside the wide orange bands, which is simulated below as the green squares.  Since prediction intervals are for single values, it is much wider than confidence intervals, which are for mean values.**

```{r ,fig.width=8,fig.height=8}

x = 1:250

c_int = predict(  lm(contrib~lastcontr,frcDat),newdata=data.frame(lastcontr=x),interval='confidence', level = 0.9)

p_int = predict(  lm(contrib~lastcontr,frcDat),newdata=data.frame(lastcontr=x),interval='prediction', level = 0.9)

plot(frcDat[,c("lastcontr","contrib")])
abline(lm(contrib~lastcontr,frcDat),col=2,lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)

lines(x, c_int[,2], col="blue", lty=2)
lines(x, c_int[,3], col="blue", lty=2)

lines(x, p_int[,2], col="orange", lty=2)
lines(x, p_int[,3], col="orange", lty=2)

frc_sample = frcDat[sample(nrow(frcDat), 100), ]
points(frc_sample$lastcontr, frc_sample$contrib, col = 3, pch=15)

```


# Problem 2: model using log-transformed attributes (20 points)

1. Use `lm()` to fit a regression model of *log-transformed* outcome (`contrib`) as a linear function of *log-transformed* last contribution and use `summary` to evaluate its results.

For the purposes of this exercise we can exclude small number of observations where `lastcontr==0`, otherwise log-transformation will result in negative infinity values for those and error from the call to `lm`. (And what does last contribution of zero represent in the first place, anyway?!  Rounded values of contributions below 1?  That's a rhetorical question aimed at data producers, no need to answer it as part of this problem set.)  When you exclude those observations with `lastcontr==0` please note in your solution how many exactly you have excluded.

```{r}

frcDat_log = subset(frcDat,lastcontr>0)
nrow(frcDat)
nrow(frcDat_log)
#excluding lastcontr == 0 removed 10 rows of data
summary(frcDat)
```
```{r}

summary(lm(log10(contrib)~log10(lastcontr),frcDat_log))

```
**The fit is good, p is very low.**

Now that we are done with that - can we compare the fits obtained from using untransformed (above) and log-transformed attributes?  Can we directly compare RSE from these two models?  What about comparing $R^2$?  What would we conclude from this? (Please consult ISLR Ch.3.1.3 if unsure)  What would be the physical meaning of model coefficients this time?  What does model intercept represent in this case, for example?  How sensible is this and how does this compare to the meaning of the same parameter (intercept) obtained when fitting on untransformed data?

**The predictions are based on log10($), so our line equation is log10(contrib) = 0.20030 + 0.82016*log10(lastcontr).  We can qualitative compare the fits between untransformed and log-transformed. To compare RSE with the linear model, we can transform it by 10^RSE as we do with 10^log10(contrib) = contrib.  We can compare R^2 directly because it is normalized to a 0 to 1 range.  The log model is slightly better at 0.5957, versus 0.5571 for linear model.  The intercept is also in log(contrib), so 10^intercept would be the intercept in terms of contrib.  So the model predicts that if the lastcontr is 1, and log(1)=0, then contrib would be 10^0.2 = 1.58.  The un-transformed line formula becomes contrib = 1.58*lastcontr^0.8216.  This formula is plotted as a log transformation in the plot below, as green squares, which overlaps the red line created by the lm function.  This un-transformed formula would suggest that a person who never contributed before would not do so this time, which could be true with a very high confidence interval, as we could include the entire world population into our dataset as people with lastcontr = 0.**

```{r}

#RSE in 'dollar'
10^0.1736
#This is lower than the RSE = 7.692 for linear model

#Intercept in 'dollar'
10^0.2
# 3.52 for linear model

```

2. Create an XY-scatterplot of log-transformed predictor and response and add corresponding regression line to it.  Compare it to the plot in untransformed coordinates obtained in Problem 1.  What would you conclude from such comparison?

```{r}

plot(  log10(frcDat_log[,c("lastcontr","contrib")])  )
abline(lm(log10(contrib)~log10(lastcontr),frcDat_log),col=2,lwd=2)

x=1:20/10
x=10^x
y=1.58*x^0.8216
points(log10(x),log10(y), col = 3, pch=15)

```
\
**The fit looks much better than the linear plot, some of the points that looked extreme, like $200 contributions, does not look like one now.**

3. Make diagnostic plots for the model fit on log-transformed outcome and the last contribution.  Compare them to the diagnostic plots generated in Problem 1 for the model fitted using original scale of measurements (untransformed). What can you conclude from this comparison about the relative quality of these two models?

```{r ,fig.width=8,fig.height=8}
old.par = par(mfrow=c(2,2))
plot(lm(log10(contrib)~log10(lastcontr),frcDat_log))
par(old.par)
```
**The residuals are much lower, with the highest magnitude at 10^1.5 = 31, compared with up to 150 in the linear model.  The QQ plot appears similar to linear model.  The scale-location plot is more flat, so residuals do not appear to significant increase with increasing last_contr.  For residuals vs leverage, the Cook's distance lines are outside the ranges of the graph, so there are fewer outliers compared with the linear model.  Overall the log model is better than the linear model**

# Problem 3: Adding second variable to the model (10 points)

To explore effects of adding another variable to the model, continue using log-transformed attributes and fit a model of log-transformed outcome (the same target campaign contribution, column `contrib` in `fund-raising.csv`) as a function of the last contribution and average contribution (both log-transformed).  Just an additive model -- no interaction term is necessary at this point. Please obtain and evaluate the summary of this model fit, confidence intervals on its parameters and its diagnostic plots. Where applicable, compare them to the model obtained above and reflect on pros and cons of including average contribution as another variable into the model.  You may find the discussion of *variance inflation factor* (VIF) in ISLR Ch.3.3.3 (Section 6) and its implementation `vif` in `car` library particularly useful in this context. 


```{r}

summary(lm(log10(contrib)~log10(lastcontr)+log10(avecontr),frcDat_log))

```

**The R^2 value of 0.6396 is better than the single var log model of 0.5957**
```{r ,fig.width=8,fig.height=8}
old.par = par(mfrow=c(2,2))

plot(lm(log10(contrib)~log10(lastcontr)+log10(avecontr),frcDat_log))

par(old.par)
```

**With multiple predictor variables, collinearity may be possible, which makes it difficult to determine some of the coefficients.  Variance inflation factor is used to detect collinearity.**

```{r}
library('car')
vif(lm(log10(contrib)~log10(lastcontr)+log10(avecontr),frcDat_log))
```

**VIF is less than 5, so we should not have collinearity issues.**
